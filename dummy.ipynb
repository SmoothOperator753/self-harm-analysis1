{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ib4Zs7QkHfAf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Flatten, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.utils import resample\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "axVxILq2HvJg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df = df[['statement', 'status']]\n",
        "df = df.rename(columns={'statement': 'content', 'status': 'sentiment'})\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(subset=['content'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j5pii1RHHvMZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', ' ', text)  # Remove numbers\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)  # Remove punctuation\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['text_clean'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "df = df[df['text_clean'].str.split().str.len() <= 200]\n",
        "df.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "33pufHMKHvO2"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['encoded_labels'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "max_sequence_length = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZZrovFQRHvRv"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text_clean'])\n",
        "token_list = tokenizer.texts_to_sequences(df['text_clean'])\n",
        "max_sequence_length = max([len(seq) for seq in token_list])\n",
        "padded_sequences = pad_sequences(token_list, maxlen=max_sequence_length, padding='pre', truncating='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, df['encoded_labels'], test_size=0.30, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcZyhF1OHvUg",
        "outputId": "7fd84493-7c64-4037-dc78-e748b0295a93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\pythin 3.10\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 23 variables whereas the saved optimizer has 44 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = load_model(\"sentiment_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H4szTfCvHvWK"
      },
      "outputs": [],
      "source": [
        "def predict_text(text):\n",
        "    text = preprocess_text(text)\n",
        "    token_list = tokenizer.texts_to_sequences([text])\n",
        "    token_padded = pad_sequences(token_list, maxlen=max_sequence_length, padding='pre', truncating='pre')\n",
        "    prediction = model.predict(token_padded)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 116ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6, 2, 3, ..., 2, 6, 5], dtype=int64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9532     6\n",
              "34662    3\n",
              "5152     3\n",
              "33044    2\n",
              "36437    3\n",
              "        ..\n",
              "26011    3\n",
              "4320     3\n",
              "31686    2\n",
              "17255    2\n",
              "7917     6\n",
              "Name: encoded_labels, Length: 12683, dtype: int32"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5712\n",
            "Recall: 0.6008\n",
            "Accuracy: 0.6943\n",
            "f1_score: 0.5827\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score\n",
        "\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(y_val, y_pred_labels, average = 'macro')  # Use 'macro' or 'weighted' for multiclass\n",
        "recall = recall_score(y_val, y_pred_labels, average = 'macro')\n",
        "accuracy = accuracy_score(y_val, y_pred_labels)\n",
        "f1_score= f1_score(y_val, y_pred_labels,average = 'macro')\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"f1_score: {f1_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.68      0.67       813\n",
            "           1       0.61      0.65      0.63       545\n",
            "           2       0.61      0.56      0.58      3191\n",
            "           3       0.90      0.86      0.88      4896\n",
            "           4       0.30      0.36      0.33       169\n",
            "           5       0.30      0.46      0.37       621\n",
            "           6       0.61      0.63      0.62      2448\n",
            "\n",
            "    accuracy                           0.69     12683\n",
            "   macro avg       0.57      0.60      0.58     12683\n",
            "weighted avg       0.71      0.69      0.70     12683\n",
            "\n",
            "[[ 553   48   47   57    7   91   10]\n",
            " [  23  354   65   18   28   54    3]\n",
            " [  74   78 1772  163   69  286  749]\n",
            " [  75   26  167 4234   13  167  214]\n",
            " [   8   26   37   11   61   19    7]\n",
            " [  86   39  103   89    8  288    8]\n",
            " [  11   11  699  117   20   46 1544]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "print(classification_report(y_val, y_pred_labels))\n",
        "print(confusion_matrix(y_val, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLnMT8U3HvZO",
        "outputId": "17b6c8cf-3093-4549-bad1-6dcc34b5dd69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Predicted Sentiment: Normal\n"
          ]
        }
      ],
      "source": [
        "sample_text = \" www./i want to live\"\n",
        "\n",
        "print(\"Predicted Sentiment:\", predict_text(sample_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b52rUd4JEqz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
